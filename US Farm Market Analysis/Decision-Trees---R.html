<!DOCTYPE html>
<html style="font-size: 16px;">
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta charset="utf-8">
    <meta name="keywords" content="Introduction​, Farms​">
    <meta name="description" content="">
    <meta name="page_type" content="np-template-header-footer-from-plugin">
    <title>Decision Trees - R</title>
    <link rel="stylesheet" href="page.css" media="screen">
<link rel="stylesheet" href="Decision-Trees---R.css" media="screen">
    <script class="u-script" type="text/javascript" src="jquery.js" defer=""></script>
    <script class="u-script" type="text/javascript" src="page.js" defer=""></script>
    <link id="u-theme-google-font" rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:100,100i,200,200i,300,300i,400,400i,500,500i,600,600i,700,700i,800,800i,900,900i|Raleway:100,100i,200,200i,300,300i,400,400i,500,500i,600,600i,700,700i,800,800i,900,900i">
    
    
    
    
    
    
    <meta name="theme-color" content="#478ac9">
    <meta property="og:title" content="Decision Trees - R">
    <meta property="og:type" content="website">
  </head>
  <body class="u-body u-custom-color-4"><header class="u-clearfix u-custom-color-2 u-header u-header" id="sec-0fb1"><div class="u-align-left u-clearfix u-sheet u-sheet-1"></div></header>
    <section class="u-clearfix u-custom-color-2 u-section-1" id="sec-fe08">
      <div class="u-clearfix u-sheet u-sheet-1">
        <h2 class="u-align-center u-text u-text-custom-color-6 u-text-1">
          <span style="font-size: 3rem;">Decision Trees - Record Data (R)</span>
        </h2>
        <p class="u-align-left u-text u-text-custom-color-3 u-text-2">This page shows the process of using R Studio to make decision trees and make predictions.<br>
          <br>Below is the code<span style="font-weight: 700;">
            <a href="files/RDecisionTree.pdf" class="u-active-none u-border-none u-btn u-button-link u-button-style u-file-link u-hover-none u-none u-text-palette-1-base u-btn-1"> (download)</a>
          </span>:&nbsp;<br>
          <br>
          <embed src="files/RDecisionTree.pdf#toolbar=0&embedded=true&zoom=140" style="-webkit-transform:scale(1);-moz-transform-scale(1)" width="100%" height="1300px" frameborder="0">
          <br>
          <br>The raw data is the labeled crop recommendation dataset.. The data has 22 labels ranging from fruits to vegetables. Total 8 variables and 1 is catogorical variable. In anther word<span style="font-weight: 400;">s, this record data is a combination of qualitative and quantitative data.&nbsp;<b style="">&nbsp;</b>
          </span>
          <br>The image shows how the raw data look like <span style="font-weight: 700;">
            <a href="files/Crop_recommendation1.csv" class="u-active-none u-border-none u-btn u-button-link u-button-style u-file-link u-hover-none u-none u-text-palette-1-base u-btn-2">(download)</a>
          </span>:<br>
          <br>
          <br>
          <br>
          <br>
          <br>
          <br>
          <br>
          <br>
          <br>
          <br>
          <br>
          <br>
          <br>
          <br>
          <br>
          <br>
          <br>
          <br>
          <br>The word "exchange", "diets", and "foode" have the most <span style="font-weight: 700;">edges</span> with arrows. In other words, these three words have the most confidence-based relationships with other words in the image.&nbsp;<br>
          <br>
          <br>
          <br>Plot the top 100 rules from apriori sorted by lift value.&nbsp;<br>
          <br>
          <br>
          <br>
          <br>
          <br>
        </p>
        <img class="u-expanded-width u-image u-image-default u-image-1" src="images/textscrennshot.png" alt="" data-image-width="1192" data-image-height="742">
        <img class="u-expanded-width u-image u-image-default u-image-2" src="images/text.png" alt="" data-image-width="1282" data-image-height="740">
      </div>
    </section>
    <section class="u-clearfix u-custom-color-2 u-section-2" id="sec-e0f8">
      <div class="u-clearfix u-sheet u-sheet-1">
        <p class="u-align-center u-text u-text-custom-color-3 u-text-1">Decision Trees<br>
        </p>
        <p class="u-align-left u-text u-text-custom-color-3 u-text-2">What​ is decision tree?<br>Every machine learning algorithm has its own benefits and reason for implementation. Decision tree algorithm is one such widely used algorithm. A decision tree is an upside-down tree that makes decisions based on the conditions present in the data (<a href="https://www.mygreatlearning.com/blog/decision-tree-algorithm/" class="u-active-none u-border-none u-btn u-button-link u-button-style u-hover-none u-none u-text-palette-1-base u-btn-1" target="_blank">GreatLearning.com</a>)<br>
          <br>
          <span style="font-weight: 700;">The depth of a decision tree is the length of the longest path from a root to a leaf. The size of a decision tree is the number of nodes in the tree.</span>
          <br>
          <br>
          <span style="font-weight: 700;">Complexity Parameter.</span> The complexity parameter (cp) in rpart is the minimum improvement in the model needed at each node. It’s based on the cost complexity of the model defined as…<br>
          <br>• For the given tree, add up the misclassification at every terminal node.<br>• Then multiply the number of splits time a penalty term (lambda) and add it to the total misclassification.<br>• The lambda is determined through cross-validation and not reported in R.<br>•The cp we see using <span style="font-style: italic;">printcp() </span>is the scaled version of lambda over the misclassifcation rate of the overall data.<br>
          <br> The cp value is a stopping parameter. It helps speed up the search for splits because it can identify splits that don’t meet this criteria and prune them before going too far.If you take the approach of building really deep trees, the default value of 0.01 might be too restrictive (<a href="https://www.learnbymarketing.com/tutorials/rpart-decision-trees-in-r/" class="u-active-none u-border-none u-btn u-button-link u-button-style u-hover-none u-none u-text-palette-1-base u-btn-2" target="_blank">Learn by Marketing.com</a>).
        </p>
      </div>
    </section>
    <section class="u-clearfix u-custom-color-2 u-section-3" id="sec-d631">
      <div class="u-clearfix u-sheet u-sheet-1">
        <p class="u-text u-text-custom-color-3 u-text-1">
          <span style="font-weight: 700;">Decision Tree One</span>
          <br>
          <br>
          <br>
        </p>
        <img class="u-file-link u-image u-image-default u-image-1" src="images/decisiontree1.png" alt="" data-image-width="1150" data-image-height="900" data-href="files/decisiontree1.png" data-target="_blank">
        <p class="u-text u-text-custom-color-3 u-text-2">The&nbsp;​first decision tree created by <i>rpart() </i>function took the default cp value, default class type and default split method. The graph took the longest time to generate since the size of the tree is quite large.<br>
          <br>SInce the tree is large, it's greate to see the cp plot to check overfitting.<br>Below is the cp plot generated from this tree:<br>
        </p>
        <img class="u-expanded-width u-file-link u-image u-image-default u-image-2" src="images/cpplot.png" alt="" data-image-width="1150" data-image-height="900" data-href="files/cpplot.png" data-target="_blank">
        <p class="u-text u-text-custom-color-3 u-text-3">From the plot, we can tell the margin is when cp = 0.019. If cp is bigger than that, the tree is smaller. Other wise, if cp is smaller than that, the tree is bigger and the result will be overfitting. cp value is one of the key features in valuing decision tree models.<br>
          <br>Let's take a look at the heatmap based on the confusion matrix of this tree:
        </p>
        <img class="u-expanded-width u-file-link u-image u-image-default u-image-3" src="images/confusionmatrix1.png" alt="" data-image-width="1150" data-image-height="900" data-href="files/confusionmatrix1.png" data-target="_blank">
      </div>
    </section>
    <section class="u-clearfix u-custom-color-2 u-section-4" id="sec-a8e4">
      <div class="u-clearfix u-sheet u-sheet-1">
        <p class="u-text u-text-custom-color-3 u-text-1">The heatmap from the confusion matrix is very nice and clean. However, the size of the tree is 22 which is a lot more than the margin value. The tree is on the edge of overfitting since the margin of the tree size is 22 or 23.<br>
          <br>
          <span style="font-weight: 700;">Decision Tree Two</span>
          <br>
        </p>
        <img class="u-file-link u-image u-image-default u-image-1" src="images/dt2new.png" alt="" data-image-width="1408" data-image-height="900" data-href="files/dt2new.png" data-target="_blank">
        <p class="u-text u-text-custom-color-3 u-text-2">The second decision tree is generated under cp=0..49, type is chosen to be "Class", and split is set to default. The size of the tree is 5. The X-val Relative Error is about 0.57. We can predicted from the small size of the tree and the cp plot that the confusion matrix and the heatmap is not going to be neat.<br>
          <br>Let's take a look at the heatmap base on the confusion matrix:<br>
        </p>
        <img class="u-file-link u-image u-image-default u-image-2" src="images/confusionmatrix2.png" alt="" data-image-width="1150" data-image-height="900" data-href="files/confusionmatrix2.png">
        <p class="u-text u-text-custom-color-3 u-text-3">This one is less neater than the first one even though the first one is overfitting. The second decision tree is underfitting since the cp is relatively large.<br>
          <br>
          <span style="font-weight: 700;">Decision Tree Three</span>
        </p>
        <img class="u-file-link u-image u-image-default u-image-3" src="images/dt3new.png" alt="" data-image-width="1408" data-image-height="900" data-href="files/dt3new.png" data-target="_blank">
        <p class="u-text u-text-custom-color-3 u-text-4"> &nbsp;The third tree - here cp is 0.02 and “information” is chosen for the split method instead of the
default which is GINI measure. The size of the tree is 21. It's not overfitting since the margin of the tree size is 22 or 23.<br>
          <br>Let's look at the heatmap based on the confusion matrix:
        </p>
        <img class="u-image u-image-default u-image-4" src="images/confusionmatrix3.png" alt="" data-image-width="1150" data-image-height="900">
      </div>
    </section>
    <section class="u-border-2 u-border-custom-color-2 u-clearfix u-custom-color-2 u-section-5" id="sec-11cd">
      <div class="u-clearfix u-sheet u-sheet-1">
        <p class="u-align-left u-text u-text-custom-color-3 u-text-1">From the heatmap distribution, we can see that this one is better than the second one but less accurate than the first one.&nbsp;<br>
          <br>Also, based on the cp plot, we know the margin of the tree size is 22 or 23, and the according cp value is from 0.01 to 0.019. I would choose the first decision tree to be the best prediction model in this case.<br>
          <br>
        </p>
        <p class="u-align-left u-text u-text-custom-color-3 u-text-2">
          <span style="font-weight: 700; font-size: 2.25rem;">Discussion</span>
          <br>Between the mathmatical methods of decision trees, the purpose of decision tree is to generate a best model to catogorize unlabeled data. The way to achieve it is to find the patterns and relationships in the existing labeled data, and apply that finding to the unkown but relative dataset, to predict the label or catogeory for the unknown dataset.&nbsp;<br>
          <br>Decision tree is an unsurpervised learning method. By repeating the process of unsupervised learning, AI can help us observe the world by precoded languages and perdict more and more accurately.&nbsp;<br>
          <br>
        </p>
      </div>
    </section>
    
    
    <footer class="u-align-center u-clearfix u-custom-color-1 u-footer u-footer" id="sec-9ddc"><div class="u-align-left u-clearfix u-sheet u-sheet-1"></div></footer>
    <section class="u-backlink u-clearfix u-grey-80">
    </section>
  </body>
</html>